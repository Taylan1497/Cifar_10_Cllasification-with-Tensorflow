{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16679fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 16:24:36.535604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/taylan/root/lib\n",
      "2023-04-30 16:24:36.535626: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/taylan/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import pickle\n",
    "import numpy as np\n",
    "#import tensorflow.compat.v1 as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#tf.disable_v2_behavior()\n",
    "\n",
    "def model():\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
    "    y_true = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "    train_mode = tf.placeholder(tf.bool)\n",
    "    \n",
    "    \n",
    "    \n",
    "    conv1 = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], padding='same')\n",
    "    conv1_bn = tf.layers.batch_normalization(conv1,momentum=0.9, training=train_mode)\n",
    "    conv1_act = tf.nn.relu(conv1_bn)\n",
    "    conv1_pool = tf.layers.max_pooling2d(conv1_act, pool_size=[2, 2], strides=2, padding='same')\n",
    "    #conv1_bn = tf.layers.batch_normalization(conv1_pool)\n",
    "    print(\"Convolution 1: \", conv1.shape)\n",
    "    print(\"Activation Shape: \", conv1_act.shape)\n",
    "    print(\"Pooling Shape: \", conv1_pool.shape)\n",
    "    print(\"Batch Normalization Shape: \", conv1_bn.shape)\n",
    "    \n",
    "    # 3, 4\n",
    "    conv2 = tf.layers.conv2d(conv1_pool,filters=64,kernel_size=[3, 3], padding='same')\n",
    "    conv2_bn = tf.layers.batch_normalization(conv2, momentum=0.9, training=train_mode)\n",
    "    conv2_act = tf.nn.relu(conv2_bn)\n",
    "    conv2_pool = tf.layers.max_pooling2d(conv2_act, pool_size=[2, 2], strides=2, padding='same')    \n",
    "    #conv2_bn = tf.layers.batch_normalization(conv2_pool)\n",
    "    print(\"Convolution 2: \", conv2.shape)\n",
    "    print(\"Activation Shape: \", conv2_act.shape)\n",
    "    print(\"Pooling Shape: \", conv2_pool.shape)\n",
    "    print(\"Batch Normalization Shape: \", conv2_bn.shape)\n",
    "  \n",
    "\n",
    "    conv3 = tf.layers.conv2d(conv2_pool, filters=128, kernel_size=[3, 3], padding='same')\n",
    "    conv3_bn = tf.layers.batch_normalization(conv3, momentum=0.9, training=train_mode)\n",
    "    conv3_act = tf.nn.relu(conv3_bn)\n",
    "    conv3_pool = tf.layers.max_pooling2d(conv3_act, pool_size=[2, 2], strides=2, padding='same')  \n",
    "    #conv3_bn = tf.layers.batch_normalization(conv3_pool)\n",
    "    print(\"Convolution 3: \", conv3.shape)\n",
    "    print(\"Activation Shape: \", conv3_act.shape)\n",
    "    print(\"Pooling Shape: \", conv3_pool.shape)\n",
    "    print(\"Batch Normalization Shape: \", conv3_bn.shape)\n",
    "    \n",
    "    \n",
    "    flat = tf.reshape(conv3_pool, [-1, 4 * 4 * 128])\n",
    "    print(\"flatten: \", flat.shape)\n",
    "\n",
    "    full_connected_1 = tf.layers.dense(flat, units=512, kernel_initializer='he_uniform', name='full_connected_1')\n",
    "    activation_4 = tf.nn.relu(full_connected_1)\n",
    "    dropout_4 = tf.layers.dropout(activation_4, rate=0.5, training=train_mode)\n",
    "    print(\"full_connected_1: \", full_connected_1.shape)\n",
    "    print(\"activation_4: \", activation_4.shape)\n",
    "    print(\"dropout_4: \", dropout_4.shape)\n",
    "\n",
    "    y_pred = tf.layers.dense(dropout_4, units=10)\n",
    "    print(\"y_pred: \", y_pred.shape)\n",
    "    return x, y_true, y_pred, train_mode, dropout_4, flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d71bd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/taylan/anaconda3/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22331/1734346203.py:19: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv1 = tf.layers.conv2d(x, filters=32, kernel_size=[3, 3], padding='same')\n",
      "/tmp/ipykernel_22331/1734346203.py:20: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  conv1_bn = tf.layers.batch_normalization(conv1,momentum=0.9, training=train_mode)\n",
      "/tmp/ipykernel_22331/1734346203.py:22: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  conv1_pool = tf.layers.max_pooling2d(conv1_act, pool_size=[2, 2], strides=2, padding='same')\n",
      "/tmp/ipykernel_22331/1734346203.py:30: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv2 = tf.layers.conv2d(conv1_pool,filters=64,kernel_size=[3, 3], padding='same')\n",
      "/tmp/ipykernel_22331/1734346203.py:31: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  conv2_bn = tf.layers.batch_normalization(conv2, momentum=0.9, training=train_mode)\n",
      "/tmp/ipykernel_22331/1734346203.py:33: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  conv2_pool = tf.layers.max_pooling2d(conv2_act, pool_size=[2, 2], strides=2, padding='same')\n",
      "/tmp/ipykernel_22331/1734346203.py:41: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  conv3 = tf.layers.conv2d(conv2_pool, filters=128, kernel_size=[3, 3], padding='same')\n",
      "/tmp/ipykernel_22331/1734346203.py:42: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  conv3_bn = tf.layers.batch_normalization(conv3, momentum=0.9, training=train_mode)\n",
      "/tmp/ipykernel_22331/1734346203.py:44: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  conv3_pool = tf.layers.max_pooling2d(conv3_act, pool_size=[2, 2], strides=2, padding='same')\n",
      "/tmp/ipykernel_22331/1734346203.py:55: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  full_connected_1 = tf.layers.dense(flat, units=512, kernel_initializer='he_uniform', name='full_connected_1')\n",
      "/tmp/ipykernel_22331/1734346203.py:57: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  dropout_4 = tf.layers.dropout(activation_4, rate=0.5, training=train_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution 1:  (?, 32, 32, 32)\n",
      "Activation Shape:  (?, 32, 32, 32)\n",
      "Pooling Shape:  (?, 16, 16, 32)\n",
      "Batch Normalization Shape:  (?, 32, 32, 32)\n",
      "Convolution 2:  (?, 16, 16, 64)\n",
      "Activation Shape:  (?, 16, 16, 64)\n",
      "Pooling Shape:  (?, 8, 8, 64)\n",
      "Batch Normalization Shape:  (?, 16, 16, 64)\n",
      "Convolution 3:  (?, 8, 8, 128)\n",
      "Activation Shape:  (?, 8, 8, 128)\n",
      "Pooling Shape:  (?, 4, 4, 128)\n",
      "Batch Normalization Shape:  (?, 8, 8, 128)\n",
      "flatten:  (?, 2048)\n",
      "full_connected_1:  (?, 512)\n",
      "activation_4:  (?, 512)\n",
      "dropout_4:  (?, 512)\n",
      "y_pred:  (?, 10)\n",
      "INFO:tensorflow:Restoring parameters from sample_data/model_save/my-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22331/1734346203.py:62: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  y_pred = tf.layers.dense(dropout_4, units=10)\n",
      "2023-04-30 16:24:44.105914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/taylan/root/lib\n",
      "2023-04-30 16:24:44.105937: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-30 16:24:44.105963: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (localhost.localdomain): /proc/driver/nvidia/version does not exist\n",
      "2023-04-30 16:24:44.106172: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 16:24:44.110963: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 16:24:44.336582: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1310720000 exceeds 10% of free system memory.\n",
      "2023-04-30 16:24:44.665595: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1310720000 exceeds 10% of free system memory.\n",
      "2023-04-30 16:24:45.011716: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 327680000 exceeds 10% of free system memory.\n",
      "2023-04-30 16:24:45.233461: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 655360000 exceeds 10% of free system memory.\n",
      "2023-04-30 16:24:45.535538: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 655360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy 70.87%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "#import tensorflow.compat.v1 as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior()\n",
    "#tf.disable_v2_behavior()\n",
    "#from Model import model\n",
    "\n",
    "def data_train_test():\n",
    "    y_train = []\n",
    "    for i in range(1, 6):\n",
    "        fd_train = open(\"sample_data/cifar_10_data/data_batch_{}\".format(i), 'rb')\n",
    "        train_dict = pickle.load(fd_train, encoding='latin1')\n",
    "        fd_train.close()\n",
    "\n",
    "        if i == 1: \n",
    "            x_train = train_dict['data']\n",
    "        else: \n",
    "            x_train = np.vstack((x_train, train_dict['data']))\n",
    "\n",
    "        y_train = y_train + train_dict['labels']\n",
    "\n",
    "    x_train = x_train.reshape((len(x_train), 3, 32, 32))\n",
    "    x_train = np.rollaxis(x_train, 1, 4).astype('float32')\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    fd = open(\"sample_data/cifar_10_data/test_batch\", 'rb')\n",
    "    dict = pickle.load(fd, encoding='latin1')\n",
    "    fd.close()\n",
    "    \n",
    "    x_test, y_test = dict['data'], dict['labels']\n",
    "    x_test = x_test.reshape((len(x_test), 3, 32, 32))\n",
    "    x_test = np.rollaxis(x_test, 1, 4).astype('float32')\n",
    "    \n",
    "\n",
    "    return x_train, y_train,x_test,y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test=data_train_test() # create data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=5000, random_state=42) # creating validation sets\n",
    "y_train, y_val, y_test = np.eye(10)[y_train], np.eye(10)[y_val],np.eye(10)[np.array(y_test)] \n",
    "\n",
    "#x_train /= 255\n",
    "#x_val /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x, y_true, y_pred, train_mode, fully_connected_1, latent_space_flat= model()\n",
    "saver = tf.train.Saver()\n",
    "tf_session = tf.Session()\n",
    "saver.restore(tf_session, 'sample_data/model_save/my-model')\n",
    "print(\"model is loaded\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# accuracy calculation\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1)), tf.float32))\n",
    "\n",
    "test_accuracy = tf_session.run(accuracy, {x: x_test, y_true: y_test, train_mode: False})\n",
    "\n",
    "print(\"Test set accuracy {:.2f}%\".format(test_accuracy*100))\n",
    "tf_session.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96635fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
